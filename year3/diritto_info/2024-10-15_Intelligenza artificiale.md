# 2024-10-15_Intelligenza artificiale

Nel 2017 il parlamento europeo ha emanato la una Risoluzione del Parlamento europeo del 16 febbraio 2017 ("Norme di diritto civile sulla robotica").

Si tratta di un insieme di raccomandazioni (quindi non sono norme vincolanti) riguardanti la robotica, in particolare vediamo due punti:

1. considerando che, dal mostro di Frankenstein ideato da Mary Shelley al mito classico di Pigmalione, passando per la storia del Golem di Praga e il robot di Karel Čapek, che ha coniato la parola, gli esseri umani hanno fantasticato sulla possibilità di costruire macchine intelligenti, spesso androidi con caratteristiche umane
2. considerando che le leggi di Asimov devono essere considerate come rivolte ai progettisti, ai fabbricanti e agli utilizzatori di robot, compresi i robot con capacità di autonomia e di autoapprendimento integrate, dal momento che tali leggi non possono essere convertite in codice macchina
    
    In breve le leggi di Asimov citano: 
    
    - Un robot non può recar danno a un essere umano né può permettere che, a causa del proprio mancato intervento, un essere umano riceva danno.
    - Un robot deve obbedire agli ordini impartiti dagli esseri umani, purché tali ordini non contravvengano alla Prima Legge.
    - Un robot deve proteggere la propria esistenza, purché questa autodifesa non contrasti con la Prima o con la Seconda Legge.

Se al posto della robotica, ci sostituiamo l’intelligenza artificiale, tali regolamenti risultato essere molto attuali.

Definiamo:

- **Dato**: è un fatto o osservazione verificabile, descrivibile con simboli
- **Informazione**: collezione di dati a cui è associato un **significato**
- **Coscienza**: informazione a cui è associato un **contesto**
- **Saggezza**: coscienza a cui è associato un **giudizio**

L’IA sta nel livello di saggezza.

I precedenti punti al giorno d’oggi, in Europa sono regolati dal GDPR e dall’AI act.

Regolare l’ambito dell’intelligenza artificiale è molto complesso sia per la sua complessità tecnica sia per i rapidi cambiamenti che sta subendo in poco tempo.

Il training è una parte fondamentale per realizzare una IA che funziona bene, è quindi necessario avere dei dataset di qualità per evitare errori e bias, ma sui dataset usati nel training spesso non c’è trasparenza e c’è il discorso della privacy.

Quando l’ia deve prendere delle decisioni vitali come dorebbe decidere? (classico problema del carrello ferroviario), per decisioni automatizzate importanti ci dovrebbe sempre essere un controllo umano.

Le decisioni **giudiziarie** **predittive** basate sulle statistiche (o sulla profilazione degli individui) sono proibite, dato che si tratta pur sempre di incertezza, a prescindere che la probabilità sia alta.

Le decisioni di **giustizia di fatti** già accaduti è già una applicazione fattibile ma è comunque necessario un controllo umano sulla decisione.

Le decisioni riguarda quanto è stato fatto bene un lavoro (non se sia giusto o sbagliato) non sono affidabili.
