# Testing

Basandosi sul documento dei requisiti è già possibile definire le modalità di collaudo del sistema, generando così un **piano di testing.**

Il piano di testing definisce in che modo le attività di testing accompagnano lo sviluppo del progetto

Vediamo alcune definizioni utili:

- **Errore**: incomprensione umana riguardo la comprensione del problema, la risoluzione del problema o nell’uso di strumenti
- **Difetto**: manifestazione software dell’errore umano (*bug*)
- **Malfunzionamento**: situazione in cui il software non si comporta come previsto a causa di un difetto

La fase di testing consiste nel ottenere un malfunzionamento, trovare il difetto relativo e cercare di capire l’errore che ha generato quel difetto.

Un test ha successo quando trova malfunzionamenti, il fatto di non trovare malfunzionamenti non assicura la loro assenza (il testing è quindi una condizione necessaria ma non sufficiente per garantire la correttezza del codice)

## Casi di test

**Casi di test** (test case): insieme di input per testare il sistema (chiamati “dati di test”) e i corrispettivi output attesi

Un criterio per generare dei test è:

- **Affidabile** se il criterio genera dei test case che danno sempre lo stesso risultato (sempre un successo o sempre un insuccesso)
- **Valido** se qualora il programma non sia corretto esiste almeno un test che fa emergere un malfunzionamento

Garantire entrambe le proprietà non è sempre banale, è quindi importante dare delle **priorità**.

Vediamo delle regole generali:

- i test devono testare le caratteristiche globali del sistema piuttosto che testare le singole componenti
- se il sistema è una nuova versione è più importante testare le caratteristiche che erano già presenti nel precedente sistema
- testare le situazione più comuni è più importante di testare casi atipici (hanno meno probabilità di accadere)

## Specifica dei casi di test

La documentazione dei casi di test dovrebbe seguire questi campi:

- Identificativo del test case
- descrizione
- precondizioni
- valori in input
- output attesi
- output riscontrato
- esito: positivo (rilevato malfunzionamento), negativo (nessun malfunzionamento)
- postcondizioni (simili agli output attesi ma verificabili sulle risorse, come database, file, device, …)
- priorità

La specifica serve sia in fase di sviluppo per identificare delle correzioni necessarie, ma anche per dimostrare che il software è fatto bene.

## Test di moduli

Un **modulo** in questo caso rappresenta un blocco di codice da testare.

Per testare un modulo occorre simulare i chiamanti del modulo (**DRIVER**) e gli utilizzatori del risultato prodotto dal modulo (**STUB**)

Esistono diverse tipologie di testing:

- Incremental testing
    - Top-down testing
    - Bottom-up testing
- Thread testing
- Stress testing
- Back-to-back testing
- Black-box testing
- White-box testing
- Verifica statica

## Incremental testing

è un modo di testare ripetutamente, ad ogni passo si aggiungono dei moduli con i relativi test case.

L’approccio **top-down** consiste nel testare prima i livelli più generici del sistema in cui temporaneamente i livelli più bassi vengono implementati come STUB (chiamate con la stessa firma dei metodi veri ma che non fanno niente) e man mano si testano i livelli più specifici

L’approccio bottom-up consiste nel testare prima i livelli più profondi del sistema in cui temporaneamente i livelli più alti vengono implementati come DRIVER (chiamanti che simulano l’ambiente reale) e man mano si testano livelli più generici

## Thread testing

Consiste nel testare tutte le possibili strade che l’esecuzione può intraprendere in base all’input.

Gli `if` nel codice rappresenta una divisione dell’esecuzione.

## Stress testing

Si basa sul fatto che mettendo il sistema sotto pressione è più probabile che si verifichino malfunzionamenti.

Si cerca si superare i limiti previsti in fase di progettazione e si vede fino a che punto il sistema regge e quali sono le conseguenze quando si verifica il fallimento

## Back to back testing

Si utilizzano diverse versione software per testare che durante lo sviluppo gli output di componenti comuni siano uguali. Se non fossero uguali significa o che le nuove aggiunte e modifiche hanno rotto qualcosa oppure che la componente in comune ha leggermente cambiato il suo scopo

## Black-box testing

Si vede il sistema come una scatola nera, baso quindi i miei test sulla specifica del sistema ancora prima passare all’implementazione.

Bisogna quindi fare un partizionamento degli input per separare tutti i tipi di input validi e invalidi

## White-box testing

I casi di test sono ottenuti da codice, si cerca quindi di testare tutti i comandi e i cammini di esecuzione del codice.

In questo metodo bisogna rispettare dei criteri:

- Copertura delle istruzioni: esercitare almeno una volta ogni istruzione durante il test
- Copertura delle decisioni: ogni percorso di esecuzione deve venir testato, nelle condizioni (gli if) devo testare sia il caso in cui entro sia il caso in cui non entro (è importante testare i valori ai limiti della condizione).
- Copertura dei cammini: bisognerebbe testate le combinazioni di tutti i percorsi, ma sono potenzialmente infiniti. Bisogna calcolare un numero minimo di test per testare le combinazioni indipendenti, tramite la **complessità ciclomatica**

### Complessità ciclomatica

Il numero minimo di test necessari per attraversare tutti i cammini indipendenti è uguale alla complessità ciclomatica che si calcola a partire dal **diagramma di flusso** del programma e si ottiene con la seguente formula

$$
\text{Complessità ciclomatica = }\text{Numero di archi} - \text{Numero di nodi} + 1
$$

(per dettagli e altre versioni leggermente diverse della formula guarda [https://it.wikipedia.org/wiki/Complessità_ciclomatica#Descrizione](https://it.wikipedia.org/wiki/Complessit%C3%A0_ciclomatica#Descrizione)

Esempio

![https://i.ibb.co/bL9T76S/image.png](https://i.ibb.co/bL9T76S/image.png)

**Numero di archi: 17** (si conta anche la freccia verso il nodo 1 perché si immagina una freccia dal nodo di fine, 13 verso l’inizio, 1 per far ripartire il programma. Da questo motivo deriva il fatto di fare +1 nella formula, altrimenti la formula cambia)

Numero di nodi: 13

Complessità ciclomatica: $17-13 + 1 = 5$

Quindi so che se faccio meno di 5 test sono certo che **non siano sufficienti**, però farne di più non assicura che sia sufficiente

## Verifica statica

Finora abbiamo visto metodi di testing durante l’esecuzione del programma, ma si può testare il codice anche prima dell’esecuzione tramite l’analisi mirata del codice sorgente (terminazione dei cicli, variabili non inizializzate, mancata deallocazione, …) ed esecuzioni mentali o a voce (assieme a collaboratori) del codice per identificare incoerenze o dubbi.
