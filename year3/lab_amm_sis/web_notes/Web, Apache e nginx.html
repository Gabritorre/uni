<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>2025-04-07_Web, Apache e nginx</title>
  <link rel="stylesheet" href="https://stackedit.io/style.css" />
</head>

<body class="stackedit">
  <div class="stackedit__left">
    <div class="stackedit__toc">
      
<ul>
<li><a href="#web-apache-e-nginx">Web, Apache e nginx</a>
<ul>
<li><a href="#il-web">Il web</a></li>
<li><a href="#web-server">Web server</a></li>
<li><a href="#apache">Apache</a></li>
<li><a href="#nginx">nginx</a></li>
<li><a href="#ssltls">SSL/TLS</a></li>
</ul>
</li>
</ul>

    </div>
  </div>
  <div class="stackedit__right">
    <div class="stackedit__html">
      <h1 id="web-apache-e-nginx">Web, Apache e nginx</h1>
<h2 id="il-web">Il web</h2>
<p>Il <strong>World Wide Web</strong> (WWW, anche abbreviato in <em>web</em>) è un sistema che consente la condivisione di documenti ipertestuali (collegati da dei link) multimediali attraverso l’infrastruttura WAN della rete Internet.</p>
<p>Il Web si basa sul protocollo <strong>HTTP (HyperText Transfer Protocol)</strong> e poggia su un’architettura <strong>Client/Server</strong>.</p>
<h3 id="http">HTTP</h3>
<p>La prima versione di HTTP (1.0) prevedeva che il client facesse una singola richiesta alla volta al server per una risorsa.</p>
<p>La versione HTTP 1.1 ha introdotto:</p>
<ul>
<li>la possibilità di effettuare più richieste per connessione</li>
<li>connessioni permanenti</li>
<li>richieste/risposte asincrone all’interno di queste connessioni.</li>
<li>obbliga i client a specificare l’hostname desiderato nella richiesta, consentendo l’implementazione del <strong>virtual hosting</strong>, dove un server può ospitare più siti internet con nomi diversi ma allo stesso indirizzo IP.</li>
</ul>
<p>Attualmente, si utilizzano <strong>HTTP 2</strong> (per oltre il 50%) e <strong>HTTP 3</strong> (usato nel 20%) che aggiungono varie migliorie.</p>
<h2 id="web-server">Web server</h2>
<p>Un <strong>WEB Server</strong> è un’applicazione che gira su un host, capace di gestisce le richieste di trasferimento di pagine web verso un client.</p>
<p>La comunicazione tra server e client avviene tramite il protocollo HTTP (porta TCP 80) o la versione più sicura, HTTPS (porta TCP 443).</p>
<p>Esistono molti programmi che fungono da Web Server, e tutti sono in grado di fornire pagine web sotto forma di stream di caratteri, che il browser sarà poi in grado di interpretarle per renderizzare le pagine web.</p>
<p>Tra i vari web server è interessante approfondire:</p>
<ul>
<li><strong>Apache HTTP Server:</strong> che fino a poco tempo fa era l’unico in grado di gestire applicazioni di vario tipo (php, python, java, ecc.) grazie alla sua tecnologia modulare.</li>
<li><strong>Internet Information Services (IIS):</strong> di Microsoft, specialmente per applicazioni .NET ma con supporto anche per altri linguaggi</li>
<li><strong>nginx:</strong> leggero, veloce per pagine statiche e dinamiche, può fungere da reverse proxy e load balancer. Diventato molto popolare negli ultimi anni.</li>
</ul>
<p>Un approccio comune per configurare un server web è l’utilizzo dello stack <strong>LAMP</strong>, acronimo di Linux, Apache, MySQL e PHP, che rappresenta l’insieme dei programmi impiegati lato server.</p>
<h2 id="apache">Apache</h2>
<p>L’<strong>Apache HTTP Server</strong> è un <strong>web server open source</strong> in grado di operare sui principali sistemi operativi.</p>
<p>La sua architettura è composta da un <strong>demone</strong> che, basandosi sul file di configurazione <code>httpd.conf</code> (o <code>apache.conf</code>), permette l’accesso a uno o più siti.</p>
<p>La sua architettura modulare permette che ogni richiesta del client attivi funzioni (organizzate in <strong>moduli</strong>) eseguite come unità indipendenti. Il <strong>core</strong> è un demone che orchestra i vari moduli eseguendo facendo <em>polling</em> per intercettare le richieste e passarle ai vari moduli.</p>
<p>Esempi di moduli possono essere, traduzione, controllo degli accessi, logging, identificare il MIME type, ecc…</p>
<p><strong>Apache 2.0</strong> ha esteso la modularità introducendo i <strong>moduli multi-processing (MPM)</strong>. Questi moduli sono sostanzialmente dei processi che possono gestire le connessioni alle porte di rete, l’accettazione delle richieste, la gestione di più richieste contemporanee e fare altre operazioni.</p>
<p>I principali MPM sono:</p>
<ul>
<li><strong>mpm_prefork</strong>: Avvia una serie di <strong>processi</strong> figlio per <strong>gestire le richieste</strong>, e ogni processo figlio serve una sola richiesta alla volta. È il più veloce per singole richieste ma può consumare molta RAM ed è adatto a moduli non thread-safe come vecchie versioni di PHP.</li>
<li><strong>mpm_worker</strong>: Utilizza i <strong>thread</strong> all’interno di processi figlio per gestire più facilmente le richieste concorrenti, richiedendo meno RAM. Tuttavia, non è adatto a moduli dinamici non thread-safe.</li>
<li><strong>mpm_event</strong>: Simile a <code>worker</code> ma utilizza un thread dedicato per gestire le connessioni attive, passando le richieste ai thread figlio solo quando necessario. È più performante di <code>worker</code> e meno esoso di <code>prefork</code>, ma anch’esso inadatto a moduli non thread-safe.</li>
</ul>
<p>Per quanto riguarda la <strong>configurazione</strong> di Apache, la <strong>DocumentRoot</strong>, solitamente impostata su <code>/var/www/html</code>, determina la posizione dei file del sito web. La configurazione del modulo <code>mpm-prefork</code> si trova in <code>/etc/apache2/mods-available/mpm-prefork.conf</code>.</p>
<p>Apache supporta i <strong>Virtual Host</strong>, che permettono a un singolo server web di ospitare più domini.</p>
<h2 id="nginx">nginx</h2>
<p>È un web server open source disponibile per i principali OS nato con l’obiettivo di essere più performante di Apache specialmente in situazioni con molte connessioni contemporanee.</p>
<p>Oltre ad agire come <strong>web server</strong> può essere utilizzato anche come:</p>
<ul>
<li><strong>reverse proxy</strong></li>
<li><strong>proxy per connessioni TCP e UDP</strong></li>
<li><strong>proxy per email</strong></li>
<li><strong>bilanciatore di carico (load balancer)</strong></li>
</ul>
<p>Proprio queste sue molteplici capacità e la facilità di installazione tramite Docker lo hanno reso estremamente popolare.</p>
<p>Per quanto riguarda la <strong>configurazione</strong>, i file principali di Nginx si trovano nella directory <code>/etc/nginx/</code>. Il file di configurazione principale è <code>nginx.conf</code>. Le varie impostazioni che puoi definire in questi file sono chiamate <strong>direttive</strong>. Una direttiva può essere <strong>semplice</strong>, se contiene un solo valore e termina con un punto e virgola:</p>
<pre><code>worker_processes 1;
</code></pre>
<p>Oppure può essere <strong>composta</strong>, in questo caso viene chiamata <strong><em>server block</em> o contesto</strong> e contiene una serie di direttive semplici racchiuse tra parentesi graffe:</p>
<pre><code>server {
	 listen        80 default_server;
	 server_name   miosito.com www.miosito.com;
	 root          /var/www/miosito.com;
	 index         index.html;
	 try_files     $uri /index.html;
}
</code></pre>
<p>Una configurazione banale per eseguire nginx in background come utente <code>nginx</code>, in ascolto sulla porta 80 e che mostri i file statici che si trovano nella cartella <code>/var/www/html:</code></p>
<pre><code>user nginx;
worker_processes 1;
error_log nginx_error.log;
http {
	 server {
		  listen 80;
		  location / {
		 	   root /var/www/html;
		  }
	 }
}
</code></pre>
<h3 id="virtual-hosting">Virtual hosting</h3>
<p>Il concetto di <strong>server block</strong> in Nginx è molto simile al <strong>virtual hosting di Apache</strong>. Questo significa che puoi ospitare più siti web sullo stesso server Nginx.</p>
<p>Un modo per farlo è definire <strong>più server blocks all’interno dello stesso file</strong> <code>nginx.conf</code>. Ad esempio, avere un blocco per <code>sito1.com</code> e un altro per <code>sitoN.com</code>, ognuno con la sua radice dei documenti, i suoi log, ecc…</p>
<p>Un approccio più pulito è quello di <strong>creare dei file separati</strong> per ogni sito nella directory <code>/etc/nginx/sites-available/</code>, e poi <strong>abilitarli</strong> creando dei <strong>link simbolici</strong> a questi file all’interno della directory <code>/etc/nginx/sites-enable/</code>.</p>
<h3 id="reverse-proxy">Reverse proxy</h3>
<p>Una delle funzionalità più sfruttate di Nginx è quella di <strong>reverse proxy</strong>. Un reverse proxy è un server che si frappone tra i client e i server interni. I client inviano richieste al reverse proxy che a sua volta si occupa di inoltrarle al server giusto, recupera la risposta e la rimanda indietro al client.</p>
<p>Questo è utile in diverse situazioni:</p>
<ul>
<li>quando le risorse di un sito sito sono distribuite su più server ma vuoi che gli utenti accedano tramite un unico indirizzo web;</li>
<li>come <strong>load balancer</strong>, per distribuire il traffico tra più server che offrono lo stesso servizio;</li>
<li>per aggiungere funzionalità a delle applicazioni esistenti, come ad esempio il <strong>supporto a HTTPS</strong> per applicazioni che non lo gestiscono nativamente.</li>
</ul>
<p>Il bilanciamento del carico serve a <strong>distribuire il traffico</strong> su più server per sfruttare al meglio le risorse, aumentare la velocità del servizio web, ridurre i tempi di attesa e renderlo più resistente ai guasti. Nginx supporta <strong>tre modalità principali</strong> di bilanciamento del carico:</p>
<ul>
<li><strong>Round-robin</strong>: le richieste vengono distribuite ai server in sequenza, uno dopo l’altro. Non garantisce la persistenza delle sessioni</li>
<li><strong>Least-connected</strong>: ogni nuova richiesta viene inviata al server che in quel momento ha il minor numero di connessioni attive. Non garantisce la persistenza delle sessioni</li>
<li><strong>Ip-hash</strong>: viene utilizzata una funzione hash che mappa IP del client con l’id del server per decidere quale server dovrà gestire la sua richiesta. In questo modo le richieste provenienti dallo stesso client vengano sempre indirizzate allo stesso server, garantendo le persistenza delle sessioni.</li>
</ul>
<p>Infine, Nginx ha anche un sistema di <strong>monitoraggio passivo</strong> dei server. Se un server non risponde correttamente, viene temporaneamente escluso dal bilanciamento del carico.</p>
<h2 id="ssltls">SSL/TLS</h2>
<p>Specialmente per applicazioni che richiedono autenticazione e trasmettono dati sensibili è importante implementare dei meccanismi di crittografia. Sebbene non offra una protezione totale, rende più difficile violare il sistema.</p>
<p><strong>Transport Layer Security (TLS)</strong> e il suo predecessore <strong>Secure Sockets Layer (SSL)</strong> sono protocolli crittografici utilizzati per stabilire una comunicazione sicura end-to-end su reti TCP/IP. Questi protocolli forniscono <strong>autenticazione</strong>, <strong>identità</strong> (tramite certificati), <strong>integrità dei dati</strong> e <strong>cifratura</strong>, operando al di sopra del livello di trasporto.</p>
<p>Alcuni esempi di implementazione di SSL/TLS sono HTTPS, SMTPS, POP3S, IMAPS.</p>
<p><strong>OpenSSL</strong> è una famosa implementazione open source dei protocolli SSL/TLS. La libreria principale è scritta in C e implementa funzioni di crittografia basilari, fornendo strumenti per funzionalità avanzate  ed è utilizzato da circa il 70% dei server della rete.</p>
<p>OpenSSL permette l’utilizzo sia di certificati rilasciati da <em>Certification Authority</em> (CA) valide, sia di certificati autogenerati. In caso di certificati autogenerati, i browser potrebbero avvertire l’utente che il certificato potrebbe non essere sicuro. Un’alternativa per ottenere certificati validi senza costi elevati è <strong>Let’s Encrypt</strong>.</p>

    </div>
  </div>
</body>

</html>
