# Algoritmo di Dijkstra

Possiamo descrivere l'algoritmo di Dijkstra nel seguente modo:
**Viene estratto un vertice alla volta, ad ogni estrazione si rilassano gli archi uscenti dal nodo estratto.**

Dijkstra fa uso di una coda di priorità $Q$ contenente le informazioni sul campo $d$ per ogni **nodo** del grafo **ancora da estrarre**.
Utilizza anche un insieme $S$ dove vengono mantenuti i **nodi già estratti**

Nota: L'algoritmo funziona solamente con archi con **pesi positivi**.
Inoltre risolve la categoria di problemi a **sorgente singola**

```c
dijkstra(G, w, s)
	init_ss(G, s)
	Q = V[G]
	S = ∅ 
	while Q != ∅
		u = extract_min(Q)
		S = S ∪ {u}
		for-each v in Adj[u]
			relax(u, v, w(u, v))
	return (d, Gπ)
```

L'algoritmo termina in quanto:
Ad ogni iterazione del `while` l'insieme `Q` diminuisce di 1.
Mentre il ciclo for avrà sempre un numero finito di iterazioni in quanto ci sarà sempre un numero finito di archi.

## Complessità

La complessità dell'algoritmo dipende dall'implementazione dell'insieme `Q`, possiamo infatti implementarlo come:
1. Heap binario
2. Array lineare

## Complessità con Heap binario

- `init_ss` avrà tempo lineare, dipendente dal numero di nodi $n$
- la `extract_min(Q)` avrà tempo $\log(n)$ in quanto va mantenuta la proprietà dell'heap, tale metodo verrà chiamato $n$ volte dal ciclo, quindi in totale si avrà una complessità $n \log (n)$
- la `relax` ha complessità $\log(n)$ in quanto va mantenuta la proprietà dell'heap, tale metodo verrà chiamato $\text{out-degree}(u)$ volte, abbiamo già osservato che la sommatoria di tutti gli $\text{out-degree}$ dei nodi del grafo è $m$, quindi in totale si avrà una complessità $m \log (n)$

La complessità totale dell'algoritmo sarà quindi

$$T(n) = n + n\log(n) + m\log(n)$$

Assumendo che il grafo sia **connesso** allora $m \geq n-1$ e quindi

$$T(n) = O(m\log(n))$$

## Complessità con array lineare

- `init_ss` avrà tempo lineare, dipendente dal numero di nodi $n$
- la `extract_min(Q)` avrà tempo $n$ in quanto va cercato il minimo, tale metodo verrà chiamato $n$ volte dal ciclo, quindi in totale si avrà una complessità $n^2$
- la `relax` ha complessità costante in quanto va aggiornato direttamente un valore dell'array, tale metodo verrà chiamato $\text{out-degree}(u)$ volte che abbiamo già osservato essere la sommatoria di tutti i gradi dei nodi è $m$, quindi in totale si avrà una complessità $m$

La complessità totale dell'algoritmo sarà quindi

$$T(n) = n + n^2 + m$$

$$T(n) = O(n^2)$$

Nota: pensare di ordinare la la coda $Q$ in modo da avere il minimo in prima posizione per ottenere una complessità $n\log n$ al posto di $n^2$ è sbagliato.
Dato che i valori all'interno di $Q$ cambiano ad ogni relax, l'ordinamento andrebbe fatto $n$ volte (alla fine di ogni iterazione del while) ottenendo così una complessità $n^2\log n$

## Confronto

Seppur a primo impatto possa sembrare sempre migliore l'implementazione con Heap binari, in realtà dipende dalla densità del grafo.
Se assumiamo che un grafo **sparso** abbia $m \approx n$
e un grafo **denso** abbia $m \approx n^2$

allora possiamo schematizzare nel seguente modo le complessità:

|  | Heap | Array |
|--|--|--|
| **Grafo sparso** | $n\log(n)$ | $n^2$ | 
| **Grafo denso** | $n^2\log(n)$ | $n^2$ |

Notiamo come per grafi **sparsi** è più conveniente utilizzare l'implementazione con **Heap** binario.
Mentre con grafi **densi** è più conveniente utilizzare l'implementazione con **Array** lineare

## Correttezza

Sia $G = (V, E, w)$ orientato, pesato sugli archi tale che i pesi $w(u, v) \geq 0$ per ogni arco $(u, v)$, Quindi solo con **pesi positivi o 0**.
Inoltre consideriamo la sorgente $s \in V$.

Allora alla fine dell'algoritmo si ha:
1. $\forall u \in V$ vale $d[u] = \delta(s, u)$
2. $G_\pi$ è un albero di cammini minimi

### Dimostrazione

Dimostriamo solo il primo punto:
Dimostrando $\forall u \in V$ che **all'atto di estrazione** di $u$ dalla coda $Q$, vale $d[u] = \delta(s, u)$, allora automaticamente varrà anche alla fine dell'algoritmo.

Supponiamo **per assurdo** che all'estrazione del nodo $u$, **per la prima volta**, si ha che $d[u] \neq \delta(s, u)$

Facciamo delle osservazioni:
1. $u$ non può essere la sorgente, in quanto vale che $d[s] = 0 = \delta(s, s)$ (non può essere $-\infty$ in quanto non ci sono pesi negativi)
2. nell'istante prima di estrarre $u$, vale che $S \neq \emptyset$ perché in $S$ ci sarà almeno la sorgente
3. $u$ sarà sicuramente raggiungibile da $s$ perché se non fosse così avremmo che $d[u] = +\infty = \delta(s, u)$

Consideriamo la seguente situazione, $u$ **è il prossimo nodo che verrà estratto**:

![enter image description here](https://i.ibb.co/Fx04639/image.png)

Abbiamo un cammino minimo $\phi$ che connette $s$ con $u$.
$x$ è un nodo appartenente a questo cammino minimo e fa parte dei nodi già estratti.
$y$ è un nodo appartenente a questo cammino minimo e fa parte dei nodi ancora da estrarre.

L'affermazione assurda ci dice che anche se $u$ è il prossimo nodo da estrarre, comunque può esistere un cammino che connette $s$ e $u$ di costo migliore.
Noi vogliamo dimostrare che se $u$ è il prossimo nodo da estrarre allora non si può trovare un cammino migliore  che connette $s$ a $u$, al massimo ce ne saranno altri con lo stesso costo, o peggiore.
È evidente che se $u$ è il prossimo nodo scelto, ci sarà un arco diretto che connette un nodo appartenente ad $S$ con $u$

Facciamo delle osservazioni che ci saranno utili per la dimostrazione:
- **a)** $$d[x] = \delta(s, x)$$
	
	perché per ipotesi $u$ deve essere il primo nodo ad infrangere la proprietà, e $u$ deve ancora essere estratto
- **b)** $$d[y] = \delta(s, y)$$

	perché essendo su un cammino minimo possiamo applicare la proprietà di convergenza: quando viene estratto il nodo $x$ viene fatta la relax sull'arco uscente che va verso $y$, otteniamo che $d[y] = \delta(s, x) + w(x, y) = \delta(s, y)$

- **c)** $$d[u] \leq d[y]$$

	Dato che il prossimo nodo da estrarre è $u$ e l'estrazione viene fatta estraendo il nodo con il campo $d$ minore allora sicuramente vale che $d[u] \leq d[y]$

- **d)** $$\delta(s, y) \leq \delta(s, u)$$
	
	perché $\delta(s, u)$ è dato dalla distanza $\delta(s, y)$ sommata ai pesi dei nodi da $y$ a $u$, ma questi ultimi pesi sono tutti $\geq 0$ per ipotesi.

- **e)** $$\delta(s, u) \leq d[u]$$

	per applicazione diretta della proprietà del limite inferiore.

Se riuscissi ad ottenere 
$$\delta(s, u) \leq d[u] \leq \delta(s, u)$$

avrei dimostrato che $d[u] = \delta(s, u)$ dimostrando l'assurdità della supposizione iniziale.
Parto applicando il punto **e)**

$$\delta(s, u) \leq d[u]$$

applicando il punto **c)**

$$\delta(s, u) \leq d[u] \leq d[y]$$

applicando il punto **b)**

$$\delta(s, u) \leq d[u] \leq \delta(s, y)$$

applicando il punto **d)**

$$\delta(s, u) \leq d[u] \leq \delta(s, y) \leq \delta(s, u)$$

ho ottenuto quindi $\delta(s, u) \leq d[u] \leq \delta(s, u)$, cioè $d[u] = \delta(s, u)$

## Shift con pesi negativi

Un possibile pensiero che potrebbe generarsi è quello di shiftare i pesi in caso di pesi negativi, così da poter essere nelle condizioni di applicare Dijkstra.
Questo non sempre da un risultato corretto, vediamo un esempio:

![enter image description here](https://i.ibb.co/SDjVHY3/image.png)

Questo primo esempio sembra funzionare, infatti shiftando di $1$ riusciamo ad ottenere la stessa distanza tra i nodi $u$ e $v$ con lo stesso cammino.
Nota che il $-3$ è dovuto al fatto che nel cammino la somma dei pesi generati dallo shift è $1 \cdot 3 = 3$

![enter image description here](https://i.ibb.co/qDdv959/image.png)

In quest'altro esempio non funziona. 
Si può notare come la correttezza dipenda dal numero di archi/nodi che compongono il cammino in quanto lo shift può influenzare più o meno archi.

**Nota**: Questa problematica non si presenta negli MST in quanto essi hanno sempre un numero fisso di archi dipendente dal numero di nodi, cioè $m = n - 1$
Per questo i pesi negativi negli MST si possono usare senza problemi.


## Esempio esecuzione Dijkstra

![enter image description here](https://i.ibb.co/XxPF5wR/image.png)


