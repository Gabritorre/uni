<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>2023-10-04_Processi e thread</title>
  <link rel="stylesheet" href="https://stackedit.io/style.css" />
</head>

<body class="stackedit">
  <div class="stackedit__left">
    <div class="stackedit__toc">
      
<ul>
<li><a href="#processi-e-thread">Processi e thread</a>
<ul>
<li><a href="#modello-a-processi">Modello a processi</a></li>
<li><a href="#gestione-dei-processi">Gestione dei processi</a></li>
<li><a href="#thread">Thread</a></li>
<li><a href="#modelli-di-threading">Modelli di threading</a></li>
</ul>
</li>
</ul>

    </div>
  </div>
  <div class="stackedit__right">
    <div class="stackedit__html">
      <h1 id="processi-e-thread">Processi e thread</h1>
<p>Un <strong>processo</strong> è un <strong>programma in esecuzione sulla CPU</strong></p>
<p>In un sistema con CPU a singolo core abbiamo un <strong>pseudo-parallelismo</strong> dei processi in quanto la CPU in un istante di tempo lavora solo su un processo alla volta ma nell’arco di più tempo la CPU continua a cambiare processo in modo da illudere una esecuzione parallela su più processi</p>
<p>Mentre in un sistema a CPU con più core (sistemi multiprocessore) abbiamo una effettiva <strong>esecuzione parallela</strong> su più processi in contemporanea.</p>
<p>Un Processo ha un proprio <strong>spazio di indirizzamento</strong> diviso in:</p>
<ul>
<li>sezione del <strong>testo</strong>: dove risiede il codice da eseguire</li>
<li>sezione dei <strong>dati</strong>: dove sono salvate le variabili e la memoria allocata dinamicamente</li>
<li>sezione dello <strong>stack</strong>: dove vengono salvate le istruzioni, e le funzioni con le proprie variabili locali</li>
</ul>
<h2 id="modello-a-processi">Modello a processi</h2>
<p>Possiamo rappresentare il software come una sequenza di processi che vengono eseguiti in coda uno dopo l’altro.</p>
<p>Nel seguente modello vediamo come 4 processi indipendenti in memoria vengono eseguiti dalla CPU uno alla volta e continuando a passare da un processo all’altro anche se l’attuale processo non è terminato (context switch).<br>
<img src="https://i.ibb.co/18rP5k5/modello-a-processi.png" alt="enter image description here"></p>
<h2 id="gestione-dei-processi">Gestione dei processi</h2>
<p>Il sistema operativo può svolgere alcune funzioni per gestire i processi tra cui:</p>
<ul>
<li>Creazione di processi</li>
<li>Distruzione di processi</li>
<li>Sospensione di processi</li>
<li>Ripresa di processi</li>
<li>Modifica della priorità di un processo</li>
<li>Blocco di processi</li>
<li>Risveglio di processi</li>
<li>Dispatching di processi</li>
<li>Interprocess communication (IPC)</li>
</ul>
<h3 id="creazione-di-un-processo">Creazione di un processo</h3>
<p>Un processo può venir creato nei seguenti casi:</p>
<ol>
<li>in fase di inizializzazione del sistema</li>
<li>per una chiamata di sistema</li>
<li>su richiesta di un utente</li>
<li>l’inizio di un job batch</li>
</ol>
<p>I processi possono essere in <em><strong>foreground</strong></em> quindi attivi oppure in <em><strong>background</strong></em>:</p>
<ul>
<li>quelli in <em>foreground</em> sono spesso processi che interagiscono con l’utente e soddisfano richieste</li>
<li>quelli in <em>background</em> sono spesso dei processi del sistema operativo che non interagiscono attivamente con l’utente ma svolgo comunque compiti importanti per far funzionare il sistema come si deve. La maggior parte di questi processi sono in continua attesa che un determinato evento accada, questi processi sono chiamati <strong>deamon</strong></li>
</ul>
<p>In Unix si usa la chiamata a sistema <strong>fork</strong> per creare un clone figlio che è la copia del processo chiamante e quindi il contenuto dello spazio di indirizzamento del padre viene <strong>copiato</strong> in un nuovo spazio di indirizzamento che viene assegnato al figlio. poi è pratica comune eseguire il comando <em>execve</em> sul processo figlio per fargli eseguire un programma specifico.</p>
<p>Il corrispettivo Windows è <strong>CreateProcess</strong> che crea il processo e carica direttamente il nuovo programma al processo, in questo caso lo spazio di indirizzamento del figlio è diverso fin da subito (non c’è nessuna copia come in Unix)</p>
<p>In entrambi i casi dopo la creazione del processo e il caricamento del programma il processo padre e figlio hanno <strong>spazi di memoria distinti</strong> anche se in alcuni casi è possibile che padre e figlio condividano delle risorse.</p>
<h3 id="terminazione-di-un-processo">Terminazione di un processo</h3>
<p>Un processo può terminare per via delle seguenti ragioni:</p>
<ol>
<li>uscita normale (volontaria)</li>
<li>uscita con errore (volontaria)</li>
<li>terminato per errore fatale (involontario)</li>
<li>terminazione forzata da un altro processo (<em>killed</em>, involontario)</li>
</ol>
<p>Quando un processo padre viene terminato involontariamente, il sistema operativo può decidere se terminare anche i figli oppure lasciarli continuare.</p>
<p>In Unix esiste una gerarchia tra i processi dove il processo <em>init</em> è la radice, mentre in windows tutti i processi sono uguali. Su windows però il padre di un processo possiede un <em>handle</em> per gestire il figlio, questo <em>handle</em> è possibile passarlo ad altri processi.</p>
<h3 id="ciclo-di-vita-di-un-processo">Ciclo di vita di un processo</h3>
<p>Un processo possiede un ciclo di vita, cioè dal momento che viene creato al momento in cui viene distrutto può assumere diversi <strong>stati</strong>:</p>
<ul>
<li><strong>Running</strong> (esecuzione): il processo è in esecuzione sulla CPU.</li>
<li><strong>Ready</strong> (pronto): il processo è pronto per essere eseguito ma attende che il sistema operativo lo metta in esecuzione</li>
<li><strong>Blocked</strong> (bloccato): il processo è in attesa che si verifichi un evento prima di poter continuare la sua esecuzione</li>
</ul>
<p>Il sistema operativo possiede una lista dei processi <strong>ready</strong> e <strong>blocked</strong></p>
<p>Possiamo individuare 4 transazioni tra gli stati appena descritti:</p>
<p><img src="https://i.ibb.co/sQ797KJ/life-cycle.png" alt="enter image description here"></p>
<ol>
<li>Il processo si blocca in attesa di un evento</li>
<li>lo scheduler dei processi seleziona un altro processo da eseguire e l’attuale processo viene messo in <em>ready</em></li>
<li>Il processo viene scelto dallo scheduler per essere eseguito (fase chiamata <strong>dispatching</strong>)</li>
<li>l’evento si è verificato e il processo è pronto a continuare la sua esecuzione</li>
</ol>
<p>ovviamente sono presente due ulteriori stati che rappresentano la <strong>fase di creazione</strong> del processo, che poi si sposterà nello stato pronto. <strong>Lo stato terminazione</strong> quando il processo ha finito le sue operazioni.</p>
<h3 id="pcb">PCB</h3>
<p>Il sistema operativo possiede una tabella chiamata <strong>process table</strong> che contiene i <strong>PCB</strong> (Process Control Block) di ogni processo in vita al momento, viene anche chiamato <strong>descrittore del processo</strong>.</p>
<p>Il PCB contiene le informazioni del processo quali: Program Counter, Stack Pointer, il PID, lo stato dei file, eventuali puntatori a padre e figli,  e tutta una serie di informazioni utili per lo scheduler quando deve far passare il processo da <em>ready</em> a <em>running</em> e vice versa</p>
<p><img src="https://i.ibb.co/CVKTckK/tabella-processi.png" alt="enter image description here"></p>
<h3 id="sospensione-di-un-processo">Sospensione di un processo</h3>
<p>Un processo può essere mandato in uno stato di <strong>sospensione</strong> che non corrisponde a nessuno dei 3 stati precedenti. Quando è sospeso, il processo viene messo da parte momentaneamente, questo può essere utile per rilevare eventuali problemi di sicurezza oppure in fase di debugging.</p>
<p>La sospensione può essere richiesta dal processo stesso oppure da un altro processo, in ogni caso deve essere un altro processo a farlo ripartire</p>
<p><img src="https://i.ibb.co/XzK5K9C/sospensione.png" alt="enter image description here"></p>
<h3 id="context-switch">Context switch</h3>
<p>il context switch è un’operazione che fa lo scheduler e che consiste nello scegliere il prossimo processo da eseguire.</p>
<p>Questa operazione è divisa in 2 fasi:</p>
<ol>
<li>la prima è di salvare lo stato dell’attuale processo in esecuzione, in modo da sapere da che punto riprendere la sua esecuzione in futuro</li>
<li>la seconda è caricare le informazioni del nuovo processo da eseguire</li>
</ol>
<p>durante questa operazione la CPU rimane libera, quindi bisogna minimizzare il tempo necessario per effettuare lo scambio per evitare di perdere troppo tempo.</p>
<h3 id="interrupts">Interrupts</h3>
<p>Gli <strong>interrupts</strong> sono dei segnali che abilitano il software a rispondere a degli avvisi hardware. Gli interrupt possono essere sincroni e asincroni:</p>
<ul>
<li><strong>sincroni</strong> se il segnale è derivato direttamente dalle operazioni del processo</li>
<li><strong>asincroni</strong> se il segnale non è derivato dalle operazioni fatte dal processo</li>
</ul>
<p>Dopo aver ricevuto un interrupt il processore completa l’istruzione corrente e poi interrompe il processo.</p>
<p>viene dato il comando al sistema operativo in base al tipo di interrupt viene scelto un <strong>gestore di interrupt</strong> in quale deciderà cosa fare.<br>
Una volta che il gestore termina viene ripresa l’esecuzione del processo che era stato momentaneamente sospeso (oppure un processo successivo)</p>
<p>Gli interrups sono solitamente collegati a fattori esterni al processore. Per riferirsi a segnali generati all’interno del processore si parla di <strong>eccezioni</strong></p>
<h3 id="interprocess-communication">InterProcess Communication</h3>
<p>Il sistema operativo offre dei meccanismi di comunicazione tra i processi.</p>
<p>Abbiamo una comunicazione tramite scambio di messaggi che può essere:</p>
<ul>
<li>una comunicazione in cui i messaggi vengono trasmessi <strong>una direzione alla volta</strong></li>
<li>una <strong>comunicazione bidirezionale</strong>, quindi ogni processo può essere sia mittente che ricevitore</li>
</ul>
<p>I messaggi possono essere:</p>
<ul>
<li><strong>bloccanti</strong> il ricevente deve comunicare al mittente che ha ricevuto il messaggio</li>
<li><strong>non bloccanti</strong> il mittente non si aspetta una risposta di avvenuta consegna</li>
</ul>
<p>L’implementazione comune di una comunicazione tra processi è la <strong>pipe</strong> cioè una memoria chiamata buffer in cui un processo ci scriverà dei dati mentre l’altro li leggerà</p>
<p>Nei sistemi distribuiti la comunicazione è più complessa, i messaggi inviati possono essere corrotti o persi, è necessario quindi un meccanismo di conferma che i dati siano stati ricevuti correttamente. Sono necessari anche dei sistemi di <em>timeout</em> per rimandare il messaggio in caso di mancata conferma.</p>
<p>Vengono utilizzate delle porte per identificare quale tipo di messaggio si sta inviando. Inoltre servirebbe autenticare il mittente del messaggio.</p>
<h2 id="thread">Thread</h2>
<p>Un <strong>thread</strong> è un blocco di istruzioni. I thread appartengono ad un processo.<br>
I thread condividono tra loro lo <strong>spazio di indirizzamento e i file aperti</strong> del processo al quale appartengono. Mentre i registri, lo stack, il program counter e lo stato è singolo per ogni thread.</p>
<p>finora quando parlavamo di esecuzione di un processo, in realtà si tratta di un thread singolo che sta eseguendo il codice del processo.</p>
<p>Possiamo vedere i processi come dei raggruppatori di risorse mentre i thread sono degli esecutori che lavorano su quelle risorse raggruppate, possiamo quindi avere più esecutori (thread) che lavorano contemporaneamente su uno spazio condiviso (<strong>multithreading</strong>)</p>
<p>su un processore a singolo core, quando un processo con più thread viene eseguito, i singoli thread vengono eseguiti a turno, proprio come succedeva con più processi. I thread però sono <strong>processi leggeri</strong> in quanto gran parte dei dati è condiviso tra i thread e quando si presenta il context switch ci sono meno cose da cambiare rispetto ad un context switch tra processi. Quindi eseguire a turno più thread è più veloce che eseguire più processi a turno.</p>

<table>
<thead>
<tr>
<th>elementi del processo</th>
<th>elementi del singolo thread</th>
</tr>
</thead>
<tbody>
<tr>
<td>spazio di indirizzamento</td>
<td>program counter</td>
</tr>
<tr>
<td>variabili globali</td>
<td>registri</td>
</tr>
<tr>
<td>file aperti</td>
<td>stack</td>
</tr>
<tr>
<td>processi figli</td>
<td>stato</td>
</tr>
<tr>
<td>allarmi in sospeso</td>
<td></td>
</tr>
<tr>
<td>segnali e gestori dei segnali</td>
<td></td>
</tr>
<tr>
<td>informazioni sugli account</td>
<td></td>
</tr>
</tbody>
</table><h3 id="ciclo-di-vita-di-un-thread">ciclo di vita di un thread</h3>
<p>Il <strong>ciclo di vita</strong> di un thread è esattamente lo stesso a quello di un processo.<br>
creazione -&gt; (pronto, esecuzione, bloccato) -&gt; termina</p>
<p>l’overhead di creazione e terminazione di un thread è molto ridotto rispetto alla creazione/terminazione di un processo. Questo perché se immaginiamo che un processo è in esecuzione, questo processo ha il suo unico thread che sta eseguendo, esso ne crea un’altro che usa lo stesso spazio di indirizzamento che in questo esatto momento è già caricato in memoria quindi è molto rapida la creazione.</p>
<p>sono presente tre sfumature dello stato bloccato:</p>
<ul>
<li><em>blocked</em>: in attesa di un evento IO</li>
<li><em>waiting</em>: in attesa a causa di un altro thread</li>
<li><em>sleeping</em>: in attesa per un tempo prefissato</li>
</ul>
<p><img src="https://i.ibb.co/bQWJ3pT/thread-ciclo-vita.png" alt="enter image description here"></p>
<h3 id="operazioni-sui-thread">Operazioni sui thread</h3>
<p>Sui threads come per i processi è possibile effettuare varie operazioni:</p>
<ul>
<li>Creazione</li>
<li>Exit (terminazione)</li>
<li>Sospensione</li>
<li>Recupero (resume)</li>
<li>Sleep</li>
<li>Risveglio</li>
</ul>
<p>Un concetto importante dei thread è la <strong>join</strong>, la join è un’operazione che viene fatta da un thread principale che serve ad aspettare che tutti gli altri thread terminino la loro esecuzione prima che il thread principale continui la sua esecuzione.</p>
<h3 id="vantaggi-di-utilizzare-i-thread">Vantaggi di utilizzare i thread</h3>
<ol>
<li>dividere un problema in più piccoli sottoproblemi che vengono assegnati a dei thread che possono risolverli in parallelo, lavorando, quindi, in parallelo sullo sullo stesso set di dati</li>
<li>creare, distruggere e scambiare i thread è molto più semplice rispetto ai processi</li>
<li>quando abbiamo un intenso uso della cpu e una intensa richiesto di I/O i thread permettono la sovrapposizione di queste due cose, aumentando così le prestazioni.</li>
</ol>
<h2 id="modelli-di-threading">Modelli di threading</h2>
<p>Ci sono 3 modi principali di implementare i thread:</p>
<ul>
<li>thread a livello utente</li>
<li>thread a livello kernel</li>
<li>thread ibridi (sia a livello utente che a livello kernel)</li>
</ul>
<h3 id="thread-a-livello-utente">Thread a livello utente</h3>
<p>In questo caso i thread vengono creati e gestiti nello spazio utente, quindi il kernel non sa della loro esistenza.<br>
Il kernel è a conoscenza solo dei processi, che sono visti con un singolo thread.</p>
<p><img src="https://i.ibb.co/93Xgmj6/user-thread.png" alt="enter image description here"></p>
<p>Abbiamo una implementazione detta <strong>molti-a-uno</strong> (molti thread ad un unico contesto di esecuzione)</p>
<p>I thread vengono create da librerie in <em>runtime</em> ed essendo create nello <em>user space</em> <strong>non possono eseguire istruzioni privilegiate</strong>.</p>
<p>Ogni processo possiede una <strong>tabella dei thread</strong> contenente le informazioni di ogni thread (PC, SC, registri, stato)</p>
<p><img src="https://i.ibb.co/xYgnrBb/user-thread-example.png" alt="enter image description here"></p>
<p><strong>vantaggi</strong>:</p>
<ul>
<li>permettere di utilizzare i thread anche in sistemi che nativamente non supportano i thread</li>
<li>le librerie possono implementare il proprio modo di schedulare i thread</li>
<li>lo scheduling dei thread è molto efficiente dato che non deve far entrare in gioco il kernel</li>
<li>è portabile. Essendo indipendente dal kernel è possibile usare lo stesso codice multithreading in sistemi diversi</li>
</ul>
<p><strong>svantaggi</strong></p>
<ul>
<li>il kernel vedendo tutto come processi a singolo thread, nel caso un thread faccia operazioni di I/O è possibile che il kernel sospenda l’intero processo a favore di un altro, interrompendo così l’esecuzione di tutti i thread del processo sospeso.</li>
<li>i thread vengono schedulati all’interno di un singolo core (prestazioni limitate)</li>
</ul>
<h3 id="thread-a-livello-kernel">Thread a livello kernel</h3>
<p>In questo caso il kernel è a conoscenza e gestisce i thread</p>
<p><img src="https://i.ibb.co/TRjcdZ8/kernel-thread.png" alt="enter image description here"></p>
<p>Abbiamo una implementazione detta <strong>uno-a-uno</strong> (unico thread a unico contesto di esecuzione)</p>
<p>Il kernel possiede una tabella dei thread (oltre alla tabella dei processi) e ogni qual volta un thread voglia creare o distruggere un thread viene fatta una chiamata a sistema e il kernel aggiornerà la tabella di conseguenza.</p>
<p><img src="https://i.ibb.co/0yqfbHg/kernel-thread-example.png" alt="enter image description here"></p>
<p><strong>vantaggi</strong>:</p>
<ul>
<li>se un thread si blocca, il kernel può decidere se eseguire un altro thread dello stesso processo oppure un thread di un altro processo. In questo modo un processo può proseguire anche se uno dei suoi thread è bloccato</li>
<li>quando un thread viene cancellato, in realtà esso viene solo marcato come non eseguibile ma la sua struttura viene conservata in modo che possa essere assegnata ad un nuovo thread, risparmiando così del tempo (evitando di crearne uno da capo)</li>
</ul>
<p><strong>svantaggi</strong>:</p>
<ul>
<li>il cambio di contesto limita li prestazioni (quando si creano e distruggono tanti thread c’è molto overhead)</li>
<li>non è portabile dato che l’implementazione può variare da kernel in kernel</li>
</ul>
<h3 id="thread-ibridi">Thread ibridi</h3>
<p>questa implementazione combina le caratteristiche delle due precedenti implementazioni.</p>
<p><img src="https://i.ibb.co/2Pxp9Tc/ibrido-thread.png" alt="enter image description here"></p>
<p>Abbiamo una implementazione molti-a-molti (più thread a livello utente e più thread a livello kernel).</p>
<p>nello spazio kernel abbiamo un <strong>thread pool</strong> cioè un gestore di thread speciali chiamati <strong>worker threads</strong>.<br>
Questi worker threads sono dei thread persistenti che non vengono distrutti quando hanno terminato il loro lavoro. Ogni volta che si vuole creare un nuovo thread, il compito del thread viene assegnato ad un worker thread già pronto che si occuperà di portarlo a termine.</p>
<p>L’utilizzo di questo thread pool migliora le prestazioni dato che non dobbiamo creare e distruggere ogni volta i thread</p>
<p><img src="https://i.ibb.co/TrC9V40/ibrido-thread-esempio.png" alt="enter image description here"></p>
<p>L’obiettivo dell’implementazione ibrida è quello di imitare le funzionalità dei thread a livello kernel ma con le prestazioni dei thread a livello utente. Per fare questo bisogna limitare transizioni inutili tra spazio utente e spazio kernel.</p>
<p>il kernel si occuperà di schedulare i thread a livello kernel mentre viene assegnato ad ogni processo un <strong>processore virtuale</strong> che permette di schedulare i thread a livello utente.</p>
<p>Quando il kernel sa che un thread è bloccato:</p>
<ol>
<li>viene fatta una <strong>upcall</strong> al processore virtuale interessato, cioè una notifica che indica quale thread è bloccato.</li>
<li>Il processore virtuale si occuperà poi di rischedulare i suoi thread.</li>
<li>Quando il thread che era bloccato è pronto per essere rieseguito viene fatta un’altra <strong>upcall</strong> per avvisare il processore virtuale avvisandolo che quel thread ora può essere rischedulato.</li>
</ol>
<p>Questa implementazione ibrida funziona anche su CPU multicore.<br>
Il problema è che c’è un uso intensivo del kernel che chiama procedure nello spazio utente.</p>
<h3 id="thread-pop-up">Thread pop-up</h3>
<p>Thread pop-up è una tecnica particolarmente utilizzata nei sistemi distribuiti lato server in cui: quando la macchina riceve un messaggio, viene creato un nuovo thread per gestirlo (chiamato thread pop-up).</p>
<p>Il vantaggio di questo utilizzo è che la latenza tra l’arrivo del messaggio e l’inizio dell’elaborazione è molto bassa.</p>

    </div>
  </div>
</body>

</html>
