# Alberi

In questo capitolo studieremo gli **alberi radicati**.
Un albero radicato una struttura dati definita come $T=(N, A)$ dove 

- $N$ è un insieme finito di **nodi**, in cui è presente un particolare nodo chiamato **radice**
- $A$ è un insieme di coppie ordinate di nodi chiamate **archi** (ordinate, nel senso che **l'arco ha un verso**)


## Caratteristiche e definizioni

### Figli di un nodo
- In un albero ogni **nodo** (tranne la radice) **possiede esattamente un padre**
- un nodo può avere zero o più figli
- il numero di figli è detto **grado del nodo**
- **foglia**: nodo senza figli (nodo di grado 0)
- **nodo interno**: nodo che ha almeno un figlio
- **nodi fratelli**: nodi che hanno lo stesso padre

### Cammini

Un **cammino** è una sequenza di nodi collegati da un arco che vanno da un nodo $u$ ad un nodo $u'$

la **lunghezza** di un cammino è il numero di archi di quel cammino.
Esiste sempre un cammino di lunghezza zero (cioè che va da un nodo al nodo stesso)

Gli **antenati** di un nodo sono tutti i nodi compresi nel cammino che va dalla radice al nodo stesso (compreso). Possiamo pensare che gli antenati di un figlio sono: padre, nonno, bisnonno, ecc...

I **discendenti** di un nodo sono tutte le "generazioni" figlie di quel nodo

**Ogni nodo è antenato e discendente di se stesso**

**profondità** di un nodo $x$ è il numero di archi dalla radice al nodo stesso

Un **livello** di un albero è l'insieme di tutti i nodi che stanno alla stessa profondità

L'**altezza** di un nodo è il numero di archi presenti dal nodo fino ad andare alla foglia più lontana
- l'altezza di un albero è l'altezza del nodo radice

## Rappresentazione grafica

![enter image description here](https://i.ibb.co/VBXGZ7w/albero.png)


## Alberi binari e k-ari

Un albero k-ario è un albero in cui ogni nodo ha al massimo $k$ figli

Un albero binario è un albero k-ario in cui $k = 2$ quindi in cui **ogni nodo ha al massimo 2 figli**
Quindi abbiamo una radice e due **sottoalberi** uno destro e uno sinistro

Un **albero k-ario completo** è un albero k-ario in cui tutte le foglie hanno la stessa profondità e ogni nodo interno ha esattamente k figli

### Esercizio 1

Trovare il numero di foglie e il numero di nodi interni di un albero k-ario completo di altezza $h$

- Per il numero di foglie graficamente si può giungere alla formula

	$$\# \text{foglie} = k^h$$

	Dimostriamolo per induzione sull'altezza dell'albero:

	**caso base**:
		il caso base avviene quando $h = 0$, quindi l'albero è costituito solo dalla radice (che è anche l'unica foglia) infatti abbiamo $k^0 = 1$

	**passo induttivo**:
	Assumo per ipotesi induttiva che la proprietà sia vera per l'altezza $h$

	$\#\text{foglie}(h) = k^h$

	voglio dimostrarla per $h+1$, cioè vogliamo dimostrare che vale

	$\#\text{foglie}(h+1) = k^{h+1}$

	Sappiamo per ipotesi induttiva che al livello $h$ dell'albero ci sono $k^h$ nodi e
dato che l'albero è completo sappiamo che tutti i nodi a livello $h$ hanno $k$ figli quindi

	$$k^h \cdot k = k^{h+1}$$

	otteniamo quindi

	$\#\text{foglie}(h+1) = k^{h+1}$

- Per il numero di nodi interni, possiamo fare la somma di tutti i nodi tranne quelli all'ultimo livello:

$$\#\text{nodi interni} =\sum_{i=0}^{h-1}k^i$$

è una serie geometrica che possiamo scrivere come:

$$\#\text{nodi interni} =\frac{k^n -1}{k-1}$$


### Esercizio 2

Trovare l'altezza di un albero k-ario completo avente $n$ foglie:

Sappiamo che il numero di foglie è dato da $k^h$

per ottenere $h$ facciamo il applichiamo il logaritmo su entrambi i membri

$$h = \log_k(\#\text{foglie})$$


## Implementazione degli alberi

Le operazioni che vogliamo implementare sugli alberi sono

- `padre(Tree P, Node v)` $\to$ Node oppure NIL
pre-condizione: il nodo deve appartenere all'albero
post-condizione: restituisce il padre di un nodo oppure NIL

- `figli(Tree P, Node v)` $\to$ Lista di Node
pre-condizione: il nodo deve appartenere all'albero
post-condizione: restituisce la lista contenente i figli del nodo


## Implementazione con array

Utilizziamo un array contenente una struttura contenente l'informazione e l'indice dell'array del padre `(info, parent)`

Quindi il seguente albero

![enter image description here](https://i.ibb.co/hy4Pp0R/alberello.png)

verrebbe rappresentato dal seguente array P

![enter image description here](https://i.ibb.co/RDyyGt3/array.png)

`P[<indice>].info` = contenuto del nodo dell'albero
`P[<indice>].parent` = indice del padre

Il parent della radice è -1
rappresentiamo la lunghezza dell'array con `P.length`
Lo spazio richiesto per questa implementazione è $\Theta(n)$

```c++
padre(Tree P, node v) {
	if (P[v].parent == -1) {
		return -1;
	}
	else {
		return P[v].parent
	}
}
```
La complessità di questo algoritmo è cotante

$$T(n) = \Theta(1)$$

```c++
figli(Tree P, node v) {
	l = []
	for(i = 0; i < P.length; i++) {
		if (P[i].parent == v) {
			l.append(i)
		}
	}
	return l
}
```

Assumendo che l'istruzione `append` sia di complessità costante la complessità del nostro algoritmo è $n$ dato che dobbiamo scorrere tutta la lista

$$T(n) = \Theta(n)$$

## Implementazione con array posizionali

Questa implementazione vale solo per gli alberi k-ari completi con $k\geq 2$. Utilizzeremo un vettore $P$ di dimensione $n$ in cui $P[v]$ contiene le informazioni dell'albero e il vettore possiede le seguenti proprietà:

- $P[0]$ è la radice dell'albero
- l'$i$-esimo figlio di un nodo $v$ si trova in posizione $k\cdot v + 1 + i$
- il padre di un nodo $f$ è dato da
	
$$\bigg\lfloor\frac{f-1}{k}\bigg\rfloor$$

![enter image description here](https://i.ibb.co/4KW1fth/implementation.png)

per esempio per sapere quale è l'indice del padre del nodo $L$:

$$\bigg\lfloor\frac{9-1}{3}\bigg\rfloor =2$$

lo spazio necessario per questa implementazione è

$$S(n) = \Theta(n)$$

Assumendo di avere le seguenti due istruzioni:

1. `P.length` = numero di nodi e quindi lunghezza dell'array
2. `P.k` = grado dei nodi

```c++
padre(Tree P, node v) {
	if (v == 0) {
		return NIL;
	}
	else {
		return floor((v-1)/P.k)
	}
}
```

Abbiamo una complessità costante

$$T(n) = \Theta(1)$$

```c++
figli(Tree P, node v) {
	l = []
	if (P.k * v + 1 >= P.length) {	// se v è una foglia
		return l
	}
	else {
		for (i = 0; i < P.k; i++) {
			l.append(P.k * v + 1 + i)
		}
		return l
	}
}
```
Assumendo che la creazione della lista e l'append siano di complessità costante.
nel caso migliore $v$ è una foglia e quindi la complessità sarebbe costante mentre nel caso peggiore dobbiamo eseguire il ciclo for lungo `k` volte. la complessità è quindi limitata dal valore di $k$

$$T(n) = O(k)$$


Un grande svantaggio delle implementazioni con gli array è che in caso di rimozione/aggiunta di elementi bisogna riallocare la memoria

## Implementazione con strutture collegate

Partiamo inizialmente con un albero che ha al massimo 2 figli per ogni nodo interno (albero binario)

definiamo una struttura `x` composta da:

- `x.p` = puntatore al padre
- `x.left` = puntatore al figlio sinistra
- `x.right` = puntatore al figlio destro
- `x.key` = informazione del nodo

la complessità spaziale per questa implementazione è $\Theta(2n)$ quindi 

$$S(n) = \Theta(n)$$

```c++
padre(Tree P, node v) {
	return v.p
}
```
complessità costante

$$T(n) = \Theta(1)$$


```c++
figli(Tree P, node v) {
	l = []
	if (v.left != NIL) {
		l.append(v.left)
	}
	if (v.right != NIL) {
		l.append(v.right)
	}
	return l
}
```

Anche in questo caso abbiamo complessità costante dato che $k$ è 2

$$T(n) = \Theta(1)$$


Con alberi con un numero non prefissato di figli abbiamo bisogno di un'altra implementazione.
Definiamo una struttura `x` composta da:

- `x.p` = puntatore al padre
- `x.left_child` = puntatore al primo figlio di sinistra
- `x.right_sibling` = puntatore al fratello nell'immediata destra
- `x.key` = informazione del nodo

la complessità spaziale per questa implementazione è:

$$S(n) = \Theta(kn)$$

```c++
padre(Tree P, node v) {
	return v.p
}
```
complessità costante

$$T(n) = \Theta(1)$$

```c++
figli(Tree P, node v) {
	l = []
	iter = v.left_child
	while (iter != NIL) {
		l.append(iter)
		iter = iter.right_sibling
	}
	return l
}
```

complessità dipende da quanti figli ha il nodo $v$

$$T(n) = \Theta(\text{grado di }v)$$

## Visita di un albero

Visitare un albero significa accedere ad ogni nodo dell'albero.

La visita di un albero ha complessità spaziale e complessità temporale $O(n)$

$$S(n) = T(n) = O(n)$$

Andremo a vedere due tipologie di visite, quella **in profondità** e quella **in ampiezza**

## Visita in profondità

la visita in profondità (DFS - *depth first search*) si può suddividere in tre tipi di visite diverse in base all'ordine in cui si visitano i nodi.

### Visita pre-order

```c++
pre_order(node r) {
	if (r != NIL) {
		//visita il nodo r
		pre_order(r.left)
		pre_order(r.right)
	}
}
```

si visita quindi prima il nodo attuale, poi il sottoalbero sinistro e poi il sottoalbero destro

![enter image description here](https://i.ibb.co/10W5yjc/pre-order.png)


### Visita in-order

```c++
in_order(node r) {
	if (r != NIL) {		
		in_order(r.left)
		//visita il nodo r
		in_order(r.right)
	}
}
```

si visita quindi prima il sottoalbero sinistro e poi il nodo centrale e infine il sottoalbero destro

![enter image description here](https://i.ibb.co/7pxjF4G/Screenshot-1.png)


### Visita post-order

```c++
post_order(node r) {
	if (r != NIL) {		
		post_order(r.left)
		post_order(r.right)
		//visita il nodo r
	}
}
```

si visita quindi prima il sottoalbero sinistro e poi il sottoalbero destro e infine il nodo centrale

![enter image description here](https://i.ibb.co/Rg2sMHW/post-order.png)


## Teorema sulla visita in profondità
 
 Sia $x$ la radice di un sottoalbero di $n$ nodi, la visita in profondità ha complessità temporale $\Theta(n)$

Dimostriamo per sostituzione il teorema.

Sia $T(n)$ il tempo richiesto dalla procedura chiamata sulla radice di un albero con $n$ nodi.

la definizione di $T(n)$ è la seguente

$$T(n) = \begin{cases}
c & \text{se } n=0 \\
T(k) + T(n-k-1) + d & \text{se } n>0 
\end{cases}$$

dove $k$ è il numero di nodi del sottoalbero sinistro e di conseguenza $n-k-1$ è il numero di nodi del sottoalbero destro (togliamo dal totale $n$ il nodi del sottoalbero sinistro $k$ e togliamo la radice (1)

Nel metodo di sostituzione dobbiamo indovinare la complessità, dato che dobbiamo visitare tutti i nodi dell'albero, l'algoritmo avrà sicuramente almeno complessità lineare:

$$T(n) = \Omega(n)$$

nella maniera più generica possibile possiamo esprime una equazione lineare come:

$$T(n) = an + b$$

dimostriamo per induzione completa su $n$:

**caso base**: quando $n = 0$
il nostro albero sarà composto dalla sola radice, e la complessità della visita sarà costante $c$ secondo la nostra definizione. L'equazione risulterà:

$$T(n) = an + b$$

$$=a\cdot0 + b$$

$$= b$$

per dimostrare il caso base pongo $b = c$

**passo induttivo**:

Assumiamo che per ogni $m<n$ valga la proprietà $T(n) = am + b$

voglio dimostrare la proprietà per $n$

la definizione ci dice che per $n>0$ abbiamo:

$$T(n) = T(k) + T(n-k-1) + d$$

dato che $k$ è sicuramente minore di $n$ ma anche $n-k-1$ è minore di $n$, per ipotesi induttiva possiamo scrivere:

$$ak + b + a(n-k-1) + b + d$$

$$ak + 2b + an-ak-a + d$$

$$an + 2b - a + d$$

voglio dimostrare che 

$$an + 2b - a + d = an + b$$

$$ 2b - a + d = b$$

$$ b - a + d = 0$$

$$ a = b + d$$

dal caso base sappiamo che $b = c$ 
quindi 

$$ a = c + d$$

sostituendo $a$ e $b$ in $T(n) = an + b$ otteniamo:

$$T(n) = (c+d)n + c$$

Abbiamo dimostrato che l'algoritmo ha complessità lineare.

## Visita in ampiezza

L'altro tipo di visita è la **visita in ampiezza** (**BFS** - breadth first search).

In questo algoritmo andiamo a visitare i nodi livello per livello, dalla radice fino alle foglie (tendenzialmente da sinistra verso destra).

Ad esempio nel seguente albero

![enter image description here](https://i.ibb.co/5KQ1CC4/alberello.png)

I nodi vengono visitati nel seguente ordine: `ALBERO`

L'implementazione classica di questo algoritmo viene fatto iterativamente utilizzando una **coda** come struttura dati.

```c++
visita_bfs(Node r) {
	Queue C = new Queue()
	enqueue(C,r)
	while(not QueueEmpty(C)) {
		u = dequeue(C)
		if (u != NIL) {
			//visita il nodo u
			enqueue(C, u.left)
			enqueue(C, u.right)
		}
	}
}
```

La complessità  è $\Theta(n)$


## Alberi binari di ricerca

Un albero binario di ricerca è un albero binario che soddisfa la seguente proprietà (chiamata proprietà di ricerca):

scelto un qualsiasi nodo $x$ dell'albero deve valere che nel **sottoalbero sinistro** sono presenti nodi con **valori minori o uguali** a $x$ mentre nel **sottoalbero destro** sono presenti nodi con **valori maggiori o uguale** a $x$

Un esempio di albero binario di ricerca è il seguente:

![](https://i.ibb.co/V27PH2B/alberello.png)


La visita **in-order** di questo tipo di albero permette di rappresentare i valore in ordine da più piccolo al più grande


Andremo a vedere varie operazioni su questo tipo di albero.
Un nodo $x$ è formato da:
- la chiave $x.\text{key}$
- il puntatore al padre$x.\text{p}$
- il puntatore al figlio sinistro $x.\text{left}$
- il puntatore al figlio destro $x.\text{right}$

### ricerca

Scriviamo l'algoritmo per la ricerca di una nodo data la chiave

**versione ricorsiva**

```c++
search(node x, value k) {
	if (x == NIL or x.key == k) {
		return x
	}
	else{
		if (x.key > k) {
			return search(x.left, k)
		}
		else {
			return search(x.right, k)
		}
	}
}
```

**versione iterativa**

```c++
search(node x, value k) {
	while(x != NIL and x.key != k) {
		if (k < x.key) {
			x = x.left
		}
		else {
			x = x.right
		}
	}
	return x
}
```

Questi algoritmi sono corretti perché la proprietà ci permette di tagliare degli interi sottoalberi garantendoci che nel sottoalberi tagliati ci saranno solo valori maggiori (a destra) o minori (sinistra)

Per analizzare la complessità di questi due algoritmi possiamo pensare che quando cerchiamo il valore stiamo seguendo un cammino dell'albero, nel caso peggiore questo cammino è il più lontano di tutti (cioè l'altezza dell'albero) quindi possiamo concludere che

$$T(n) = O(h)$$

dove $h$ è l'altezza dell'albero


### Massimo

Scriviamo l'algoritmo per trovare il massimo di un albero binario di ricerca

```c++
// pre-condizione: x deve appartenere all'albero
maximum(node x) {
	while (x.right != NIL) {
		x = x.right
	}
	return x
}
```

Il nodo con la chiave massima sarà il nodo più a destra nell'albero

### Minimo

Scriviamo l'algoritmo per trovare il minimo di un albero binario di ricerca

```c++
// pre-condizione: x deve appartenere all'albero
minimium(node x) {
	while (x.left != NIL) {
		x = x.left
	}
	return x
}
```
Il nodo con la chiave minima sarà il nodo più a sinistra nell'albero

la correttezza è sempre garantita dalla proprietà dell'albero binario di ricerca

Dato che stiamo sempre visitando un cammino dell'albero, il caso peggiore sarà il cammino più lungo quindi

$$T(n) = O(h)$$

### Successore

In un albero binario di ricerca che ha tutti i nodi con chiavi distinte, il successore di un nodo $x$ è la più piccola chiave maggiore di $x.\text{key}$ 


Abbiamo due casi per determinare il successore.

1. se $x$ ha un figlio destro, allora il successore è il minimo nel sottoalbero destro
2. se $x$ non ha un figlio destro, allora il successore (se esiste) si trova risalendo l'albero fino alla prima "svolta" a destra.
(con svolta si intende che fino a che il nodo attualmente puntato è figlio destro allora bisogna continuare a salire, quando il nodo è figlio sinistro allora ci si perché suo padre sarà il successore)

nota che se $x$ è il nodo massimo, esso non ha successore.


```c++
// pre-condizione: x deve appartenere all'albero
successore(node x) {
	if (x.right != NIL) {	//caso 1
		return minimum(x.right)
	}
	else {	//caso 2
		y = x.p		//y sarà sempre il padre di x
		while (y != NIL and x == y.right) {	// continua fino a che o il padre non esiste oppure fino a che non si trova una "svolta" a destra
			x = y
			y = x.p
		}
		return y
	}
}
```

Nel primo `if` abbiamo la complessità del metodo `minimum` che abbiamo visto essere $O(h)$. Anche per l'else però abbiamo la complessità di un cammino (che nel caso peggiore sarà il cammino più lungo) quindi anche qui abbiamo $O(h)$

$$T(n) = O(h)$$


### predecessore

In un albero binario di ricerca che ha tutti i nodi con chiavi distinte, il predecessore di un nodo $x$ è la più grande chiave minore di $x.\text{key}$ 

nota che se $x$ è il nodo minimo, esso non ha predecessore.


Il procedimento è molto simile a quello per trovare il successore

```c++
// pre-condizione: x deve appartenere all'albero
predecessore(node x) {
	if (x.left!= NIL) {	//caso 1
		return maximun(x.left)
	}
	else {	//caso 2
		y = x.p		//y sarà sempre il padre di x
		while (y != NIL and x == y.left) {	// continua fino a che o il padre non esiste oppure fino a che non si trova una "svolta" a destra
			x = y
			y = x.p
		}
		return y
	}
}
```

Analogamente abbiamo
$$T(n) = O(h)$$


## Inserimento

Scriviamo l'algoritmo per inserire un nuovo nodo nell'albero rispettando la sua proprietà.

Ci serviamo di un puntatore alla radice (utile per gestire l'albero vuoto): `T.root`

Assumiamo che il nuovo nodo da inserire $z$ sia già stato inizializzato con i puntatori a `NIL` e con la chiave già impostata.

```c++
inserimento(Tree T, node z) {
	y = NIL	//rappresenterà il padre del nodo z
	x = T.root
	while (x != NIL) {
		y = x
		if (z.key < x.key) {
			x = x.left
		}
		else {
			x = x.right
		}
	}
	z.p = y
	if (y == NIL) {	//se l'albero è vuoto allora z sarà la radice
		T.root = z
	}
	else {
		if (z.key < y.key) {
			y.left = z
		}
		else {
			y.right = z
		}
	}
}
```

la complessità è data dal ciclo while, quel ciclo visita un cammino dell'albero, nel caso peggiore è il cammino più lungo, quindi 

$$T(n) = O(h)$$
